const axios = require('axios');
const fs = require('fs');
const os = require('os');
const path = require('path');
const createChecksum = require('./createChecksum');
const { applyUpdates } = require('../../shared/helpers');

module.exports = (config, firebase, db) => {
  const SCAN_SERVICE_URL = config.SCAN_SERVICE_URL;
  const API_MAX_REQUEST = 100;
  const API_RATE_WINDOW_MS = 60000;
  const UPDATE_LOG_SECOND = 10;
  const BATCH_SIZE = 200;

  return {
    scanAllFiles,
  };

  /**
   * Scans all files for viruses
   *
   * force - if true then previously scanned files will be rescanned
   * maxFiles - maximum number of files to scan (useful when testing)
   * forceChecksumCreation - if true, files with existing checksums will be rescanned and reprocessed
   */
  async function scanAllFiles(force = false, maxFiles = 999999, forceChecksumCreation = false) {
    console.log('Starting file scan...');

    const started = Date.now();
    let lastUpdate = started;

    const bucket = firebase.storage().bucket(config.STORAGE_URL);
    const processed = [];
    let exception = 'none';

    try {
      await createLogFile(bucket, started, processed, exception);
      console.log('Initial log file created.');

      let commands = [];
      let countApiCall = 0;
      const maxCommands = BATCH_SIZE;

      const [files] = await bucket.getFiles();
      console.log(`Retrieved ${files.length} files from bucket.`);

      let scanResult;
      for (let i = 0; i < files.length; i++) {
        let file = files[i];

        if (file.name.startsWith('virusScanningLogs')) {
          continue;  // Skip log files
        }

        try {
          // Check if file already has a checksum in Firestore
          const docRef = db.collection('checksums').doc(file.name);
          const doc = await docRef.get();
          if (doc.exists && !forceChecksumCreation) {
            processed.push({
              name: file.name,
              scanned: getScannedDateTime(doc.data().created_at.toDate()),
              status: 'Checksum already exists',
            });
            continue;
          }
        } catch (err) {
          console.warn(`Error checking checksum for file ${file.name}: ${err.message}`);
          processed.push({
            name: file.name,
            scanned: getScannedDateTime(Date.now()),
            status: `Error checking checksum: ${err.message}`,
          });
          continue;
        }

        if (force || file.metadata.metadata.scanned === undefined || forceChecksumCreation) {
          if (countApiCall >= API_MAX_REQUEST) {
            console.log('API rate limit reached. Waiting for rate window...');
            countApiCall = 0;
            await delayMS(API_RATE_WINDOW_MS);
            console.log('Resuming API calls...');
          }

          try {
            console.log(`Scanning file: ${file.name}`);
            scanResult = await axios.post(SCAN_SERVICE_URL, {
              filename: file.name,
              projectId: config.PROJECT_ID,
            });
          } catch (e) {
            scanResult = { error: e.message };
            console.error(`Error scanning file ${file.name}: ${e.message}`);
          }
          countApiCall++;

          if (scanResult.data.status === 'clean') {
            console.log(`File ${file.name} is clean. Calculating checksum...`);
            const [fileContent] = await file.download();
            const checksum = createChecksum(fileContent);

            commands.push({
              command: 'set',
              ref: db.collection('checksums').doc(file.name),
              data: {
                filepath: file.name,
                checksum,
                created_at: firebase.firestore.Timestamp.fromDate(new Date()),
              },
            });
            console.log(`File ${file.name} is not clean. Status: ${scanResult.data.status}`);
          }

          processed.push({
            name: file.name,
            scanned: getScannedDateTime(Date.now()),
            status: scanResult.status || scanResult.error,
          });

          if (commands.length >= maxCommands) {
            console.log(`Applying ${commands.length} batched updates.`);
            await applyUpdates(db, commands);
            commands = [];
          }
        } else {
          processed.push({
            name: file.name,
            scanned: getScannedDateTime(file.metadata.metadata.scanned),
            status: file.metadata.metadata.status || null,
          });
        }

        if (processed.length >= maxFiles) {
          console.log(`Processed ${processed.length} files. Reached maxFiles limit.`);
          break;
        }

        const diffSecond = Math.round((Date.now() - lastUpdate) / 1000);
        if (diffSecond >= UPDATE_LOG_SECOND) {
          await createLogFile(bucket, started, processed, exception);
          lastUpdate = Date.now();
        }
      }

      if (commands.length > 0) {
        console.log(`Applying final ${commands.length} batched updates.`);
        await applyUpdates(db, commands);
      }

    } catch (e) {
      exception = e;
      console.error(`Exception occurred: ${e.message}`);
    }

    await createLogFile(bucket, started, processed, exception, true);
    console.log('Final log file created.');
  }

  /**
   * Delay for n milliseconds
   * @param {number} n
   */
  function delayMS(n) {
    return new Promise(resolve => setTimeout(resolve, n));
  }

  /**
   * Converts the 'scanned' metadata into a human-readable datetime format
   * @param {null|string} meta
   * @returns null|string
   */
  function getScannedDateTime(meta) {
    if (meta) {
      const scanned = new Date(parseInt(meta));
      const date = scanned.toJSON().slice(0, 10).split('-').reverse().join('/');
      const time = scanned.toLocaleTimeString('en-GB', { timeZone: 'Europe/London' });
      return date + ' ' + time;
    }
    return null;
  }

  /**
   * Creates a log file for the specified files that have been processed
   *
   * @param {bucket} bucket - the bucket that was scanned
   * @param {Date} started - the date/time the scanning started
   * @param {array} processed - the files that were processed (to log)
   * @param {string|object} exception - the exception during scanning files (to log)
   * @param {boolean} finished - if false, 'In Progress...' will be written to the log
   */
  async function createLogFile(bucket, started, processed, exception = 'none', finished = false) {
    try {
      const startDate = new Date(started);
      const endDate = new Date();

      const content = `
Virus Scanning Log

Scan service url: ${SCAN_SERVICE_URL}
Start time: ${startDate.toISOString()}
End time: ${endDate.toISOString()}

Processed (total: ${processed.length}):

${finished ? '' : '*** Scanning in progress ***'}

${JSON.stringify(processed, null, 2)}

Exception:

${JSON.stringify(exception, null, 2)}
      `;

      const isoDatetime = endDate.toISOString().replace(/:/g, '-');
      const fileName = `${isoDatetime}.json`;
      const tempFilePath = path.join(os.tmpdir(), fileName);
      fs.writeFileSync(tempFilePath, content);

      console.log(`Uploading log file: ${fileName}`);
      await bucket.upload(tempFilePath, {
        destination: 'virusScanningLogs/' + fileName,
      });

      fs.unlinkSync(tempFilePath);
      console.log(`Log file ${fileName} uploaded and local file deleted.`);

      await delayMS(1000);
    } catch (err) {
      console.error(`Failed to create log file: ${err.message}`);
    }
  }
};
