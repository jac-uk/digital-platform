import request from 'request-promise';
import fs from 'fs';
import os from 'os';
import path from 'path';

export default (config, firebase) => {

  const SCAN_SERVICE_URL = config.SCAN_SERVICE_URL;
  const API_MAX_REQUEST = 100;
  const API_RATE_WINDOW_MS = 60000;
  const UPDATE_LOG_SECOND = 10; // There's a write limit (once per second) to the same object name
  const BATCH_SIZE = 200; // Size of batch for Firestore updates

  return {
    scanAllFiles,
  };

  /**
   * Scans all files for viruses
   *
   * force - if true then previously scanned files will be rescanned
   * maxFiles - maximum number of files to scan (useful when testing)
   */
  async function scanAllFiles(force = false, maxFiles = 999999) {

    console.log('...starting...');

    const started = Date.now();
    let lastUpdate = started;

    // open the storage bucket
    const bucket = firebase.storage().bucket(config.STORAGE_URL);

    const processed = [];
    let exception = 'none';

    // console.log('Creating initial log file...');
    await createLogFile(bucket, started, processed, exception);
    // console.log('Initial log file created.');

    // Accumulate updates in memory
    let commands = [];
    let countApiCall = 0;
    const maxCommands = BATCH_SIZE;

    try {
      // console.log('Fetching files from bucket...');
      const [files] = await bucket.getFiles();
      // console.log(`Retrieved ${files.length} files from bucket.`);

      let scanResult;
      for (let i = 0; i < files.length; i++) {
        let file = files[i];

        // Skip log files
        if (file.name.startsWith('virusScanningLogs')) {
          // console.log(`Skipping log file: ${file.name}`);
          continue;
        }

        if (force || file.metadata.metadata.scanned === undefined) {

          if (countApiCall >= API_MAX_REQUEST) {
            // console.log('API rate limit reached. Waiting for rate window...');
            countApiCall = 0;
            await delayMS(API_RATE_WINDOW_MS);
            // console.log('Resuming API calls...');
          }

          // make the HTTP request to scan the file
          try {
            // console.log(`Scanning file: ${file.name}`);
            scanResult = await axios.post(SCAN_SERVICE_URL, {
              filename: file.name,
              projectId: config.PROJECT_ID,
            });
            // console.log(`Scan result for file ${file.name}: ${scanResult.status}`);
          } catch (e) {
            scanResult = { error: e.message };
            // console.error(`Error scanning file ${file.name}: ${e.message}`);
          }
          countApiCall++;

          // If the file is clean, download the file content
          if (scanResult.data.status === 'clean') {
            // console.log(`File ${file.name} is clean. Calculating checksum...`);
            const [fileContent] = await file.download();
            const checksum = createChecksum(fileContent);

            // Store the checksum in memory
            commands.push({
              command: 'set',
              ref: db.collection('checksums').doc(file.name),
              data: {
                filepath: file.name,
                checksum,
                created_at: firebase.firestore.Timestamp.fromDate(new Date()),
              },
            });

            // Log when a write to the checksums collection is about to happen
            console.log(`Preparing to write checksum for file ${file.name} to Firestore.`);

          } else {
            // console.log(`File ${file.name} is not clean. Status: ${scanResult.data.status}`);
          }

          processed.push({
            name: file.name,
            scanned: getScannedDateTime(Date.now()),
            status: scanResult.status || scanResult.error,
          });

          // Apply updates if the batch size is reached
          if (commands.length >= maxCommands) {
            // Log batch updates
            console.log(`Applying ${commands.length} batched updates.`);
            await applyUpdates(db, commands);
            // console.log('Batched updates applied.');
            commands = [];
          }

        } else {
          processed.push({
            name: file.name,
            scanned: getScannedDateTime(file.metadata.metadata.scanned),
            status: file.metadata.metadata.status || null,
          });
        }

        if (processed.length >= maxFiles) {
          // console.log(`Processed ${processed.length} files. Reached maxFiles limit.`);
          break;
        }

        // update the log file every X seconds
        const diffSecond = Math.round((Date.now() - lastUpdate) / 1000);
        if (diffSecond >= UPDATE_LOG_SECOND) {
          // console.log('Updating log file...');
          await createLogFile(bucket, started, processed, exception);
          lastUpdate = Date.now();
          // console.log('Log file updated.');
        }
      }

      // Apply remaining updates if any
      if (commands.length > 0) {
        // Log final batch updates
        console.log(`Applying final ${commands.length} batched updates.`);
        await applyUpdates(db, commands);
        // console.log('Final batched updates applied.');
      }

    } catch (e) {
      exception = e;
      // console.error(`Exception occurred: ${e.message}`);
    }

    // console.log('Creating final log file...');
    await createLogFile(bucket, started, processed, exception, true);
    // console.log('Final log file created.');

  }

  /**
   * Delay for n milliseconds
   * @param {number} n
   */
  function delayMS(n) {
    return new Promise(resolve => setTimeout(resolve, n));
  }

  /**
   * Converts the 'scanned' metadata into a human-readable datetime format
   * @param {null|string} meta
   * @returns null|string
   */
  function getScannedDateTime(meta) {
    if (meta) {
      const scanned = new Date(parseInt(meta));
      const date = scanned.toJSON().slice(0, 10).split('-').reverse().join('/');
      const time = scanned.toLocaleTimeString('en-GB', { timeZone: 'Europe/London' });
      return date + ' ' + time;
    }
    return null;
  }

  /**
   * Creates a log file for the specified files that have been processed
   *
   * @param {bucket} bucket - the bucket that was scanned
   * @param {Date} started - the date/time the scanning started
   * @param {array} processed - the files that were processed (to log)
   * @param {string|object} exception - the exception during scanning files (to log)
   * @param {boolean} finished - if false, 'In Progress...' will be written to the log
   */
  async function createLogFile(bucket, started, processed, exception = 'none', finished = false) {

    const startDate = new Date(started);
    const endDate = new Date(); // Current date/time for end

    const content = `
Virus Scanning Log

Scan service url: ${SCAN_SERVICE_URL}
Start time: ${startDate.toISOString()}
End time: ${endDate.toISOString()}

Processed (total: ${processed.length}):

${finished ? '' : '*** Scanning in progress ***'}

${JSON.stringify(processed, null, 2)}

Exception:

${JSON.stringify(exception, null, 2)}
    `;

    // save log to local temp file
    const isoDatetime = endDate.toISOString().replace(/:/g, '-'); // Replace ':' to avoid invalid filename characters
    const fileName = `${isoDatetime}.json`;
    const tempFilePath = path.join(os.tmpdir(), fileName);
    fs.writeFileSync(tempFilePath, content);

    // upload log file to storage
    // console.log(`Uploading log file: ${fileName}`);
    await bucket.upload(tempFilePath, {
      destination: 'virusScanningLogs/' + fileName,
    });

    // delete local temp file
    fs.unlinkSync(tempFilePath);

    // pause 1 second after updating the log file because this function is called multiple times
    // and we are only allowed to update the log file max. 1 time per second
    // ref: https://cloud.google.com/storage/docs/concepts-techniques#object-updates
    await delayMS(1000);
  }

};
